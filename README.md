Projeto: Pipeline Completo de Prepara√ß√£o de Dados para Machine Learning
An√°lise de Dados Imobili√°rios com Indicadores Econ√¥micos

üìÑ Sobre o Projeto
Este reposit√≥rio cont√©m um projeto de Ci√™ncia de Dados de ponta a ponta que demonstra as melhores pr√°ticas na prepara√ß√£o de dados para modelagem de Machine Learning. O objetivo √© construir um pipeline robusto, modular e bem documentado, cobrindo desde a coleta de dados de m√∫ltiplas fontes at√© a engenharia de atributos e a divis√£o estrat√©gica dos conjuntos de dados.

Utilizamos um conjunto de dados hipot√©tico de im√≥veis, que √© enriquecido com indicadores macroecon√¥micos (taxa SELIC) obtidos via API do Banco Central do Brasil, para criar um dataset rico e pronto para ser usado em modelos preditivos de regress√£o.

üöÄ Etapas do Pipeline de Prepara√ß√£o de Dados
O projeto segue rigorosamente uma s√©rie de etapas para garantir a qualidade e a consist√™ncia dos dados:

1. Coleta e Integra√ß√£o de Dados:

Combina√ß√£o de um CSV local com dados de im√≥veis e dados da taxa SELIC obtidos em tempo real da API p√∫blica do Banco Central do Brasil.

2. Limpeza e Tratamento:

Valores Ausentes: Compara√ß√£o entre remo√ß√£o e imputa√ß√£o, com a escolha final pela imputa√ß√£o por mediana para preservar a integridade do dataset.

Outliers: Detec√ß√£o via m√©todo IQR (Intervalo Interquartil) e remo√ß√£o de valores discrepantes para evitar distor√ß√µes no modelo.

Padroniza√ß√£o: Uniformiza√ß√£o de formatos de texto (caixa baixa, remo√ß√£o de espa√ßos) e convers√£o de datas para um tipo padr√£o (datetime).

3. Codifica√ß√£o de Vari√°veis Categ√≥ricas:

An√°lise comparativa entre LabelEncoder e OneHotEncoder, selecionando o segundo para converter a vari√°vel bairro em formato num√©rico sem criar uma rela√ß√£o ordinal artificial.

4. Normaliza√ß√£o e Padroniza√ß√£o:

Teste e visualiza√ß√£o do impacto do MinMaxScaler e StandardScaler. A padroniza√ß√£o com StandardScaler foi a escolhida por sua robustez e adequa√ß√£o a uma gama maior de algoritmos.

5. Engenharia de Atributos:

Cria√ß√£o de duas novas features (preco_por_m2 e idade_anuncio_dias) para agregar maior poder preditivo e capturar rela√ß√µes de neg√≥cio relevantes.

6. Divis√£o dos Dados:

Particionamento do dataset em conjuntos de Treino (70%), Valida√ß√£o (15%) e Teste (15%).

Discuss√£o sobre as estrat√©gias de Holdout e K-Fold Cross-Validation, recomendando a combina√ß√£o de ambas para uma avalia√ß√£o de modelo mais confi√°vel.

üõ†Ô∏è Tecnologias Utilizadas
Linguagem: Python 3.9+

Bibliotecas Principais:

pandas e numpy para manipula√ß√£o de dados

scikit-learn para pr√©-processamento e divis√£o dos dados

requests para consumo de API

matplotlib e seaborn para visualiza√ß√£o de dados

‚öôÔ∏è Como Executar o Projeto
Clone o reposit√≥rio:

Bash

git clone https://github.com/seu-usuario/nome-do-repositorio.git
cd nome-do-repositorio
Crie e ative um ambiente virtual (recomendado):

Bash

# Criar ambiente
python -m venv venv

# Ativar no Windows
venv\Scripts\activate

# Ativar no macOS/Linux
source venv/bin/activate
Instale as depend√™ncias:

Bash

pip install pandas numpy requests scikit-learn matplotlib seaborn
Execute o script ou notebook:
O c√≥digo pode ser executado como um script Python (.py) ou dentro de um ambiente interativo como o Jupyter Notebook (.ipynb).

‚ú® Conclus√£o T√©cnica
Este projeto demonstrou um pipeline completo e profissional de prepara√ß√£o de dados. As principais decis√µes t√©cnicas foram:

Coleta de Dados: Enriquecemos dados locais de im√≥veis com a taxa SELIC via API do BCB, criando um dataset com contexto micro e macroecon√¥mico.

Limpeza de Dados: Optamos pela imputa√ß√£o pela mediana para tratar valores ausentes, preservando o tamanho do dataset. Outliers de pre√ßo foram removidos usando o crit√©rio de IQR para evitar distor√ß√µes.

Codifica√ß√£o Categ√≥rica: O OneHotEncoder foi escolhido para a vari√°vel bairro, pois evita a cria√ß√£o de uma rela√ß√£o ordinal artificial, o que √© crucial para a maioria dos modelos.

Escalonamento: O StandardScaler foi o m√©todo selecionado para padronizar as vari√°veis num√©ricas, por sua robustez e por ser um pr√©-requisito comum em muitos algoritmos de Machine Learning.

Engenharia de Atributos: Foram criadas as features preco_por_m2 e idade_anuncio_dias, que agregam valor ao capturar rela√ß√µes de neg√≥cio importantes (valor relativo e temporalidade).

Divis√£o dos Dados: A estrat√©gia recomendada √© a combina√ß√£o de Holdout com K-Fold Cross-Validation. O Holdout isola um conjunto de teste final, enquanto o K-Fold √© usado sobre os dados de treino para uma avalia√ß√£o e otimiza√ß√£o de modelo mais confi√°veis.

O DataFrame final est√° limpo, pr√©-processado e enriquecido, pronto para ser utilizado no treinamento de modelos de regress√£o para prever pre√ßos de im√≥veis com maior precis√£o e robustez.

üìú Licen√ßa
Este projeto est√° sob a licen√ßa MIT. Veja o arquivo LICENSE para mais detalhes.